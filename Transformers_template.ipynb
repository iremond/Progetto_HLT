{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, BertConfig, AutoConfig\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/irene/.cache/huggingface/datasets/csv/default-9117625add939e31/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "117cdd2515d84433aee2d2447788079c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/irene/.cache/huggingface/datasets/csv/default-3cb4956ee4561a2a/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06a2d889848c4ba3b11cc1995c86bf39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_dev = load_dataset(\"csv\", data_files=\"dataset/subtaskA_clean_dev_cased.csv\")\n",
    "df_test = load_dataset(\"csv\", data_files=\"dataset/subtaskA_clean_test_cased.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data partioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Id', 'comment_text', 'conspiratorial'],\n",
       "        num_rows: 1289\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Id', 'comment_text', 'conspiratorial'],\n",
       "        num_rows: 553\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val = df_dev['train'].train_test_split(test_size=0.3, seed=42) # inserire random state\n",
    "train_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = train_val[\"train\"]\n",
    "df_val = train_val[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.rename_column(\"comment_text\", \"text\")\n",
    "df_train = df_train.rename_column(\"conspiratorial\", \"labels\")\n",
    "df_val = df_val.rename_column(\"comment_text\", \"text\")\n",
    "df_val = df_val.rename_column(\"conspiratorial\", \"labels\")\n",
    "df_test = df_test.rename_column(\"comment_text\", \"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nome = 'distilbert'\n",
    "model_name = 'distilbert-base-multilingual-cased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6875a1e9755f442c9ef8b91d25e5db1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9773943c97e44364ae312c26b965b1b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/466 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55a971dbbf3a48d2b082eff3628fab52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f8ed212858c468f99290362bb0cebd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97aad0daa6204930b07727e33f0e54c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1289 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3a36010fb7b4d67a0bede0c81ace8eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/553 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c807be51ae7f4097b69a01e6e7c950ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/460 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train = df_train.map(tokenize_function, batched=True)\n",
    "tokenized_val = df_val.map(tokenize_function, batched=True)\n",
    "tokenized_test = df_test.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Id', 'text', 'labels', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 1289\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small_train_dataset = tokenized_train.shuffle(seed=42).select(range(6))\n",
    "# small_eval_dataset = tokenized_val.shuffle(seed=42).select(range(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"{nome}-finetuned\",\n",
    "    evaluation_strategy = \"epoch\", # monitor the evaluation metrics during fine-tuning at the end of each epoch\n",
    "    save_strategy = \"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    num_train_epochs=15,\n",
    "    load_best_model_at_end=True, # the best model might not be the one at the end of training => we load the best saved model\n",
    "    metric_for_best_model='eval_f1',\n",
    "    seed=42\n",
    "    #per_device_train_batch_size # default 8\n",
    "    #per_device_eval_batch_size # default 8\n",
    "    #learning_rate=0.0005, # default 0.00005\n",
    "    #weight_decay=0.0001 # default 0 # disastro\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.dropout = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-multilingual-cased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.27.4\",\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ced2a7490c964b11929526e0233d6bd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/542M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-multilingual-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, config=config)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    return AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "  # takes as input model predictions, applies argmax to them and comput F-Score between predictions and true labels\n",
    "  f1_metric = evaluate.load(\"f1\")\n",
    "  predictions, labels = eval_pred\n",
    "  predictions = np.argmax(predictions, axis=1)\n",
    "  return f1_metric.compute(predictions=predictions, references=labels, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\irene\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bb49e5ca13645c69898d67f9935d24c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m<timed eval>:1\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\irene\\anaconda3\\lib\\site-packages\\transformers\\trainer.py:1633\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[0;32m   1630\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[0;32m   1631\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[0;32m   1632\u001b[0m )\n\u001b[1;32m-> 1633\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   1634\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m   1635\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[0;32m   1636\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[0;32m   1637\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[0;32m   1638\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\irene\\anaconda3\\lib\\site-packages\\transformers\\trainer.py:1902\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1900\u001b[0m         tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(model, inputs)\n\u001b[0;32m   1901\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1902\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[0;32m   1904\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   1905\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   1906\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m   1907\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   1908\u001b[0m ):\n\u001b[0;32m   1909\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   1910\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32mc:\\Users\\irene\\anaconda3\\lib\\site-packages\\transformers\\trainer.py:2645\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2642\u001b[0m     \u001b[39mreturn\u001b[39;00m loss_mb\u001b[39m.\u001b[39mreduce_mean()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m   2644\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss_context_manager():\n\u001b[1;32m-> 2645\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(model, inputs)\n\u001b[0;32m   2647\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mn_gpu \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   2648\u001b[0m     loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mmean()  \u001b[39m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\irene\\anaconda3\\lib\\site-packages\\transformers\\trainer.py:2677\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[0;32m   2675\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2676\u001b[0m     labels \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 2677\u001b[0m outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs)\n\u001b[0;32m   2678\u001b[0m \u001b[39m# Save past state if it exists\u001b[39;00m\n\u001b[0;32m   2679\u001b[0m \u001b[39m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[0;32m   2680\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpast_index \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\irene\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\irene\\anaconda3\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:763\u001b[0m, in \u001b[0;36mDistilBertForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    756\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m    757\u001b[0m \u001b[39m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m    758\u001b[0m \u001b[39m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m    759\u001b[0m \u001b[39m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m    760\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    761\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[1;32m--> 763\u001b[0m distilbert_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdistilbert(\n\u001b[0;32m    764\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[0;32m    765\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m    766\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m    767\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m    768\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    769\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m    770\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m    771\u001b[0m )\n\u001b[0;32m    772\u001b[0m hidden_state \u001b[39m=\u001b[39m distilbert_output[\u001b[39m0\u001b[39m]  \u001b[39m# (bs, seq_len, dim)\u001b[39;00m\n\u001b[0;32m    773\u001b[0m pooled_output \u001b[39m=\u001b[39m hidden_state[:, \u001b[39m0\u001b[39m]  \u001b[39m# (bs, dim)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\irene\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\irene\\anaconda3\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:583\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    579\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m    581\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(input_ids, inputs_embeds)  \u001b[39m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[1;32m--> 583\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer(\n\u001b[0;32m    584\u001b[0m     x\u001b[39m=\u001b[39;49membeddings,\n\u001b[0;32m    585\u001b[0m     attn_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m    586\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m    587\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    588\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m    589\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m    590\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\irene\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\irene\\anaconda3\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:359\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[39mif\u001b[39;00m output_hidden_states:\n\u001b[0;32m    357\u001b[0m     all_hidden_states \u001b[39m=\u001b[39m all_hidden_states \u001b[39m+\u001b[39m (hidden_state,)\n\u001b[1;32m--> 359\u001b[0m layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[0;32m    360\u001b[0m     x\u001b[39m=\u001b[39;49mhidden_state, attn_mask\u001b[39m=\u001b[39;49mattn_mask, head_mask\u001b[39m=\u001b[39;49mhead_mask[i], output_attentions\u001b[39m=\u001b[39;49moutput_attentions\n\u001b[0;32m    361\u001b[0m )\n\u001b[0;32m    362\u001b[0m hidden_state \u001b[39m=\u001b[39m layer_outputs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m    364\u001b[0m \u001b[39mif\u001b[39;00m output_attentions:\n",
      "File \u001b[1;32mc:\\Users\\irene\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\irene\\anaconda3\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:295\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[1;34m(self, x, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    286\u001b[0m \u001b[39mParameters:\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[39m    x: torch.tensor(bs, seq_length, dim)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[39m    torch.tensor(bs, seq_length, dim) The output of the transformer block contextualization.\u001b[39;00m\n\u001b[0;32m    293\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    294\u001b[0m \u001b[39m# Self-Attention\u001b[39;00m\n\u001b[1;32m--> 295\u001b[0m sa_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[0;32m    296\u001b[0m     query\u001b[39m=\u001b[39;49mx,\n\u001b[0;32m    297\u001b[0m     key\u001b[39m=\u001b[39;49mx,\n\u001b[0;32m    298\u001b[0m     value\u001b[39m=\u001b[39;49mx,\n\u001b[0;32m    299\u001b[0m     mask\u001b[39m=\u001b[39;49mattn_mask,\n\u001b[0;32m    300\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m    301\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    302\u001b[0m )\n\u001b[0;32m    303\u001b[0m \u001b[39mif\u001b[39;00m output_attentions:\n\u001b[0;32m    304\u001b[0m     sa_output, sa_weights \u001b[39m=\u001b[39m sa_output  \u001b[39m# (bs, seq_length, dim), (bs, n_heads, seq_length, seq_length)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\irene\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_history = trainer.state.log_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g7/5_cysqs52xjbryhl7rbvtvd80000gn/T/ipykernel_40972/2467079435.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"Epoch\": epoch, \"Loss\": loss, \"Dataset\": \"Training\"}, ignore_index=True)\n",
      "/var/folders/g7/5_cysqs52xjbryhl7rbvtvd80000gn/T/ipykernel_40972/2467079435.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"Epoch\": epoch, \"Loss\": loss, \"Dataset\": \"Validation\"}, ignore_index=True)\n",
      "/var/folders/g7/5_cysqs52xjbryhl7rbvtvd80000gn/T/ipykernel_40972/2467079435.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"Epoch\": epoch, \"Loss\": loss, \"Dataset\": \"Training\"}, ignore_index=True)\n",
      "/var/folders/g7/5_cysqs52xjbryhl7rbvtvd80000gn/T/ipykernel_40972/2467079435.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"Epoch\": epoch, \"Loss\": loss, \"Dataset\": \"Validation\"}, ignore_index=True)\n",
      "/var/folders/g7/5_cysqs52xjbryhl7rbvtvd80000gn/T/ipykernel_40972/2467079435.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"Epoch\": epoch, \"Loss\": loss, \"Dataset\": \"Training\"}, ignore_index=True)\n",
      "/var/folders/g7/5_cysqs52xjbryhl7rbvtvd80000gn/T/ipykernel_40972/2467079435.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"Epoch\": epoch, \"Loss\": loss, \"Dataset\": \"Validation\"}, ignore_index=True)\n",
      "/var/folders/g7/5_cysqs52xjbryhl7rbvtvd80000gn/T/ipykernel_40972/2467079435.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"Epoch\": epoch, \"Loss\": loss, \"Dataset\": \"Training\"}, ignore_index=True)\n",
      "/var/folders/g7/5_cysqs52xjbryhl7rbvtvd80000gn/T/ipykernel_40972/2467079435.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"Epoch\": epoch, \"Loss\": loss, \"Dataset\": \"Validation\"}, ignore_index=True)\n",
      "/var/folders/g7/5_cysqs52xjbryhl7rbvtvd80000gn/T/ipykernel_40972/2467079435.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"Epoch\": epoch, \"Loss\": loss, \"Dataset\": \"Training\"}, ignore_index=True)\n",
      "/var/folders/g7/5_cysqs52xjbryhl7rbvtvd80000gn/T/ipykernel_40972/2467079435.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"Epoch\": epoch, \"Loss\": loss, \"Dataset\": \"Validation\"}, ignore_index=True)\n",
      "/var/folders/g7/5_cysqs52xjbryhl7rbvtvd80000gn/T/ipykernel_40972/2467079435.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"Epoch\": epoch, \"Loss\": loss, \"Dataset\": \"Training\"}, ignore_index=True)\n",
      "/var/folders/g7/5_cysqs52xjbryhl7rbvtvd80000gn/T/ipykernel_40972/2467079435.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"Epoch\": epoch, \"Loss\": loss, \"Dataset\": \"Validation\"}, ignore_index=True)\n",
      "/var/folders/g7/5_cysqs52xjbryhl7rbvtvd80000gn/T/ipykernel_40972/2467079435.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"Epoch\": epoch, \"Loss\": loss, \"Dataset\": \"Training\"}, ignore_index=True)\n",
      "/var/folders/g7/5_cysqs52xjbryhl7rbvtvd80000gn/T/ipykernel_40972/2467079435.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"Epoch\": epoch, \"Loss\": loss, \"Dataset\": \"Validation\"}, ignore_index=True)\n",
      "/var/folders/g7/5_cysqs52xjbryhl7rbvtvd80000gn/T/ipykernel_40972/2467079435.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"Epoch\": epoch, \"Loss\": loss, \"Dataset\": \"Training\"}, ignore_index=True)\n",
      "/var/folders/g7/5_cysqs52xjbryhl7rbvtvd80000gn/T/ipykernel_40972/2467079435.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"Epoch\": epoch, \"Loss\": loss, \"Dataset\": \"Validation\"}, ignore_index=True)\n",
      "/var/folders/g7/5_cysqs52xjbryhl7rbvtvd80000gn/T/ipykernel_40972/2467079435.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"Epoch\": epoch, \"Loss\": loss, \"Dataset\": \"Training\"}, ignore_index=True)\n",
      "/var/folders/g7/5_cysqs52xjbryhl7rbvtvd80000gn/T/ipykernel_40972/2467079435.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"Epoch\": epoch, \"Loss\": loss, \"Dataset\": \"Validation\"}, ignore_index=True)\n",
      "/var/folders/g7/5_cysqs52xjbryhl7rbvtvd80000gn/T/ipykernel_40972/2467079435.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"Epoch\": epoch, \"Loss\": loss, \"Dataset\": \"Training\"}, ignore_index=True)\n",
      "/var/folders/g7/5_cysqs52xjbryhl7rbvtvd80000gn/T/ipykernel_40972/2467079435.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"Epoch\": epoch, \"Loss\": loss, \"Dataset\": \"Validation\"}, ignore_index=True)\n",
      "/var/folders/g7/5_cysqs52xjbryhl7rbvtvd80000gn/T/ipykernel_40972/2467079435.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"Epoch\": epoch, \"Loss\": loss, \"Dataset\": \"Training\"}, ignore_index=True)\n",
      "/var/folders/g7/5_cysqs52xjbryhl7rbvtvd80000gn/T/ipykernel_40972/2467079435.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"Epoch\": epoch, \"Loss\": loss, \"Dataset\": \"Validation\"}, ignore_index=True)\n",
      "/var/folders/g7/5_cysqs52xjbryhl7rbvtvd80000gn/T/ipykernel_40972/2467079435.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"Epoch\": epoch, \"Loss\": loss, \"Dataset\": \"Training\"}, ignore_index=True)\n",
      "/var/folders/g7/5_cysqs52xjbryhl7rbvtvd80000gn/T/ipykernel_40972/2467079435.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"Epoch\": epoch, \"Loss\": loss, \"Dataset\": \"Validation\"}, ignore_index=True)\n",
      "/var/folders/g7/5_cysqs52xjbryhl7rbvtvd80000gn/T/ipykernel_40972/2467079435.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"Epoch\": epoch, \"Loss\": loss, \"Dataset\": \"Training\"}, ignore_index=True)\n",
      "/var/folders/g7/5_cysqs52xjbryhl7rbvtvd80000gn/T/ipykernel_40972/2467079435.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"Epoch\": epoch, \"Loss\": loss, \"Dataset\": \"Validation\"}, ignore_index=True)\n",
      "/var/folders/g7/5_cysqs52xjbryhl7rbvtvd80000gn/T/ipykernel_40972/2467079435.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"Epoch\": epoch, \"Loss\": loss, \"Dataset\": \"Training\"}, ignore_index=True)\n",
      "/var/folders/g7/5_cysqs52xjbryhl7rbvtvd80000gn/T/ipykernel_40972/2467079435.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"Epoch\": epoch, \"Loss\": loss, \"Dataset\": \"Validation\"}, ignore_index=True)\n",
      "/var/folders/g7/5_cysqs52xjbryhl7rbvtvd80000gn/T/ipykernel_40972/2467079435.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"Epoch\": epoch, \"Loss\": loss, \"Dataset\": \"Training\"}, ignore_index=True)\n",
      "/var/folders/g7/5_cysqs52xjbryhl7rbvtvd80000gn/T/ipykernel_40972/2467079435.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"Epoch\": epoch, \"Loss\": loss, \"Dataset\": \"Validation\"}, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.697200</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.669174</td>\n",
       "      <td>Validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.635500</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.670862</td>\n",
       "      <td>Validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0.587900</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>0.672889</td>\n",
       "      <td>Validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>0.539400</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>0.677192</td>\n",
       "      <td>Validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>0.466300</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>0.680526</td>\n",
       "      <td>Validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6</td>\n",
       "      <td>0.411400</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>0.690356</td>\n",
       "      <td>Validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>0.356700</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7</td>\n",
       "      <td>0.708966</td>\n",
       "      <td>Validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8</td>\n",
       "      <td>0.321200</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8</td>\n",
       "      <td>0.732528</td>\n",
       "      <td>Validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9</td>\n",
       "      <td>0.293900</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9</td>\n",
       "      <td>0.758814</td>\n",
       "      <td>Validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>0.272400</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>0.784720</td>\n",
       "      <td>Validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>11</td>\n",
       "      <td>0.249000</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>11</td>\n",
       "      <td>0.810367</td>\n",
       "      <td>Validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>12</td>\n",
       "      <td>0.233400</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12</td>\n",
       "      <td>0.833654</td>\n",
       "      <td>Validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>13</td>\n",
       "      <td>0.192100</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>13</td>\n",
       "      <td>0.852435</td>\n",
       "      <td>Validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>14</td>\n",
       "      <td>0.191500</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>14</td>\n",
       "      <td>0.865037</td>\n",
       "      <td>Validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>15</td>\n",
       "      <td>0.180900</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>15</td>\n",
       "      <td>0.871067</td>\n",
       "      <td>Validation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Epoch      Loss     Dataset\n",
       "0      1  0.697200    Training\n",
       "1      1  0.669174  Validation\n",
       "2      2  0.635500    Training\n",
       "3      2  0.670862  Validation\n",
       "4      3  0.587900    Training\n",
       "5      3  0.672889  Validation\n",
       "6      4  0.539400    Training\n",
       "7      4  0.677192  Validation\n",
       "8      5  0.466300    Training\n",
       "9      5  0.680526  Validation\n",
       "10     6  0.411400    Training\n",
       "11     6  0.690356  Validation\n",
       "12     7  0.356700    Training\n",
       "13     7  0.708966  Validation\n",
       "14     8  0.321200    Training\n",
       "15     8  0.732528  Validation\n",
       "16     9  0.293900    Training\n",
       "17     9  0.758814  Validation\n",
       "18    10  0.272400    Training\n",
       "19    10  0.784720  Validation\n",
       "20    11  0.249000    Training\n",
       "21    11  0.810367  Validation\n",
       "22    12  0.233400    Training\n",
       "23    12  0.833654  Validation\n",
       "24    13  0.192100    Training\n",
       "25    13  0.852435  Validation\n",
       "26    14  0.191500    Training\n",
       "27    14  0.865037  Validation\n",
       "28    15  0.180900    Training\n",
       "29    15  0.871067  Validation"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=[\"Epoch\", \"Loss\", \"Dataset\"])\n",
    "\n",
    "for log_data in log_history:\n",
    "  epoch = int(log_data[\"epoch\"])\n",
    "  if \"loss\" in log_data.keys():\n",
    "    loss = log_data[\"loss\"]\n",
    "    df = df.append({\"Epoch\": epoch, \"Loss\": loss, \"Dataset\": \"Training\"}, ignore_index=True)\n",
    "  if \"eval_loss\" in log_data.keys():\n",
    "    loss = log_data[\"eval_loss\"]\n",
    "    df = df.append({\"Epoch\": epoch, \"Loss\": loss, \"Dataset\": \"Validation\"}, ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "df.to_html(f'loss_{nome}.html')\n",
    "\n",
    "display(HTML(f'loss_{nome}.html'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loss lineplot\n",
    "sns.lineplot(data=df, x=\"Epoch\", y=\"Loss\", hue=\"Dataset\")\n",
    "plt.xticks(range(1, 16))\n",
    "plt.xlabel('Epoca')\n",
    "plt.savefig(f'loss_curves_{nome}.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
